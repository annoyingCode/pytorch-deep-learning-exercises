{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/06_pytorch_transfer_learning_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNqPNlYylluR"
   },
   "source": [
    "# 06. PyTorch Transfer Learning Exercises\n",
    "\n",
    "Welcome to the 06. PyTorch Transfer Learning exercise template notebook.\n",
    "\n",
    "There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.\n",
    "\n",
    "> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can.\n",
    "\n",
    "## Resources and solutions\n",
    "\n",
    "* These exercises/solutions are based on [section 06. PyTorch Transfer Learning](https://www.learnpytorch.io/06_pytorch_transfer_learning/) of the Learn PyTorch for Deep Learning course by Zero to Mastery.\n",
    "\n",
    "**Solutions:** \n",
    "\n",
    "Try to complete the code below *before* looking at these.\n",
    "\n",
    "* See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/ueLolShyFqs).\n",
    "* See an example [solutions notebook for these exercises on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/06_pytorch_transfer_learning_exercise_solutions.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwmoMhW8IqSu"
   },
   "source": [
    "## 1. Make predictions on the entire test dataset and plot a confusion matrix for the results of our model compared to the truth labels. \n",
    "* **Note:** You will need to get the dataset and the trained model/retrain the model from notebook 06 to perform predictions.\n",
    "* Check out [03. PyTorch Computer Vision section 10](https://www.learnpytorch.io/03_pytorch_computer_vision/#10-making-a-confusion-matrix-for-further-prediction-evaluation) for ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqtAWBUJgaF1",
    "outputId": "14cc75f3-e109-4e84-c941-2598df3557b3"
   },
   "outputs": [],
   "source": [
    "# Import required libraries/code\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Try to get torchinfo, install it if it doesn't work\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
    "try:\n",
    "    from going_modular.going_modular import data_setup, engine\n",
    "except:\n",
    "    # Get the going_modular scripts\n",
    "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
    "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    !mv pytorch-deep-learning/going_modular .\n",
    "    !rm -rf pytorch-deep-learning\n",
    "    from going_modular.going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "O10_T_xSKJlf",
    "outputId": "fd30e756-e542-4b2b-d974-1ed38451fecf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrzg3TaSKLAh"
   },
   "source": [
    "### Get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lt_CNQ4rKPmg",
    "outputId": "a1364d91-3afa-4401-94cb-94e4df837f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\pizza_steak_sushi directory exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "food_data_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if food_data_path.is_dir():\n",
    "    print(f\"{food_data_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {food_data_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        zip_ref.extractall(image_path)\n",
    "\n",
    "    # Remove .zip file\n",
    "    os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
    "\n",
    "# Setup Dirs\n",
    "train_dir = food_data_path / \"train\"\n",
    "test_dir = food_data_path / \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGaMWWaoKQlM"
   },
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VNIQNEQVKVXu"
   },
   "outputs": [],
   "source": [
    "# Create a transforms pipeline\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Njd5lHTcKW23",
    "outputId": "fbc224df-8243-4e7b-90cd-49adc000fd47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2010e5ee8d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2010e5ef810>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and testing DataLoader's as well as get a list of class names\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
    "                                                                               batch_size=32) # set mini-batch size to 32\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ciw2DiRHKaSE"
   },
   "source": [
    "### Get and prepare a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "6e25b4bb0d254191a793696a0f4f00ce",
      "37424313e66f474da42cfe1b512f09df",
      "58fd00f6a9114192a4fa757c1f669bff",
      "f115ea4b5fad4bb1910fca49ed3da8a1",
      "e8eba8e353e940ff9287929e41e4d656",
      "bc33539914a947ee89c271f10ea6a2bb",
      "6e03cb60fab94b7e92ce16c8178922dd",
      "5d464254c31d4516899643112fa0e958",
      "06df3ad4b7454556a43b6d61640b12f8",
      "0bdc7325c839439589a16c88876d6bd5",
      "873a483782894789bf0dee546a1b2d50"
     ]
    },
    "id": "snUuRXd8Kdk5",
    "outputId": "eac2a1e6-5607-437e-90b5-41639d17e5a8"
   },
   "outputs": [],
   "source": [
    "# Setup the model with pretrained weights and send it to the target device \n",
    "model_0 = torchvision.models.efficientnet_b0(pretrained=True).to(device)\n",
    "# model_0 # uncomment to output (it's very long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IbRhGvy_KeVL"
   },
   "outputs": [],
   "source": [
    "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
    "for param in model_0.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "G1-6xV3ZKeSX"
   },
   "outputs": [],
   "source": [
    "# Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Get the length of class_names (one output unit for each class)\n",
    "output_shape = len(class_names)\n",
    "\n",
    "# Recreate the classifier layer and seed it to the target device\n",
    "model_0.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True), \n",
    "    torch.nn.Linear(in_features=1280, \n",
    "                    out_features=output_shape, # same number of output units as our number of classes\n",
    "                    bias=True)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQFaXX8CKePi"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "exxU79eaKeM6"
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "ae21171f17de45d895ab7a319dade609",
      "f9c60d9c0aed49faa993fd865fb09174",
      "755366e3f75e44c2b7a79bce78d77d11",
      "4a05e8d965124327a2329cf9e1eec984",
      "fe93ec079b384ac38a6f4d0e505431ff",
      "88dea77f1bcf44ffb69654515ee34f54",
      "2678a567b0414e1d9cfbfc2ecf5ffd30",
      "ce621be138a84f33b24c05b2d9cfd5f0",
      "1fa41d239a3a4845904434d057476a75",
      "f4827c6e36a1463fb0c82347f64230a2",
      "cea8f9c48bd8429998352a090173f537"
     ]
    },
    "id": "ComVkVtuKeKG",
    "outputId": "6d43205a-4e9f-4627-999a-40d07380cd58"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9bb95dad1d4791a7cf1331abfcd472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0910 | train_acc: 0.4336 | test_loss: 0.9266 | test_acc: 0.6913\n",
      "Epoch: 2 | train_loss: 0.8804 | train_acc: 0.7734 | test_loss: 0.8270 | test_acc: 0.7945\n",
      "Epoch: 3 | train_loss: 0.7750 | train_acc: 0.8086 | test_loss: 0.7520 | test_acc: 0.8049\n",
      "Epoch: 4 | train_loss: 0.7355 | train_acc: 0.7109 | test_loss: 0.6591 | test_acc: 0.8968\n",
      "Epoch: 5 | train_loss: 0.6373 | train_acc: 0.7969 | test_loss: 0.6311 | test_acc: 0.8864\n",
      "[INFO] Total training time: 129.362 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set the random seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Setup training and save the results\n",
    "model_0_results = engine.train(model=model_0,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       test_dataloader=test_dataloader,\n",
    "                       optimizer=optimizer,\n",
    "                       loss_fn=loss_fn,\n",
    "                       epochs=5,\n",
    "                       device=device)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFS4lE_IKyE_"
   },
   "source": [
    "### Make predictions on the entire test dataset with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "DwZuCluFu375"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c49dcb9fb1f4f50aacb49cb47958bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "test_preds = []\n",
    "test_preds_probs = []\n",
    "test_true = []\n",
    "wrong_preds = []\n",
    "\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds_logits = model_0(X)\n",
    "        preds_probs = preds_logits.softmax(dim=1)\n",
    "        preds_labels = preds_probs.argmax(dim=1)\n",
    "\n",
    "        test_preds_probs.append(preds_probs.cpu())\n",
    "        test_preds.append(preds_labels.cpu())\n",
    "        test_true.append(y.cpu())\n",
    "\n",
    "test_preds = torch.cat(test_preds)\n",
    "test_true = torch.cat(test_true)\n",
    "test_preds_probs = torch.cat(test_preds_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb2bQ1b5K2WP"
   },
   "source": [
    "### Make a confusion matrix with the test preds and the truth labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5I2jpYAcM07s"
   },
   "source": [
    "Need the following libraries to make a confusion matrix:\n",
    "* torchmetrics - https://torchmetrics.readthedocs.io/en/stable/\n",
    "* mlxtend - http://rasbt.github.io/mlxtend/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qcKYZGWuK2P8",
    "outputId": "88c33b26-0b76-42d7-8a27-fb3073b1fc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlxtend version: 0.23.1\n"
     ]
    }
   ],
   "source": [
    "# See if torchmetrics exists, if not, install it\n",
    "try:\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
    "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
    "except:\n",
    "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlxtend version: {mlxtend.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOYVew4xMxgI",
    "outputId": "d3b393b8-09c3-46f7-c799-2f91ee4d30e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n"
     ]
    }
   ],
   "source": [
    "# Import mlxtend upgraded version\n",
    "import mlxtend \n",
    "print(mlxtend.__version__)\n",
    "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "_5LU9-5Xu7dP"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "confmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')\n",
    "confmat_tensor = confmat(preds=test_preds,\n",
    "                         target=test_true)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy \n",
    "    class_names=class_names, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqlStPo-gbrF"
   },
   "source": [
    "## 2. Get the \"most wrong\" of the predictions on the test dataset and plot the 5 \"most wrong\" images. You can do this by:\n",
    "* Predicting across all of the test dataset, storing the labels and predicted probabilities.\n",
    "* Sort the predictions by *wrong prediction* and then *descending predicted probabilities*, this will give you the wrong predictions with the *highest* prediction probabilities, in other words, the \"most wrong\".\n",
    "* Plot the top 5 \"most wrong\" images, why do you think the model got these wrong?\n",
    "\n",
    "You'll want to:\n",
    "* Create a DataFrame with sample, label, prediction, pred prob\n",
    "* Sort DataFrame by correct (does label == prediction)\n",
    "* Sort DataFrame by pred prob (descending)\n",
    "* Plot the top 5 \"most wrong\" image predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['steak',\n",
       "  'sushi',\n",
       "  'steak',\n",
       "  'sushi',\n",
       "  'sushi',\n",
       "  'sushi',\n",
       "  'steak',\n",
       "  'steak',\n",
       "  'steak'],\n",
       " ['pizza',\n",
       "  'pizza',\n",
       "  'pizza',\n",
       "  'pizza',\n",
       "  'pizza',\n",
       "  'steak',\n",
       "  'sushi',\n",
       "  'sushi',\n",
       "  'sushi'],\n",
       " [0.4, 0.438, 0.405, 0.41, 0.449, 0.452, 0.466, 0.398, 0.55])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the tensor with values which don't match (Misclassification)\n",
    "wrong_preds = torch.ne(test_preds, test_true)\n",
    "\n",
    "# Get the class labels by using masking technique\n",
    "wrong_preds_labels = [class_names[label] for label in test_preds[wrong_preds_indices]]\n",
    "true_labels = [class_names[label] for label in test_true[wrong_preds_indices]]\n",
    "\n",
    "# Get the indices of the misclassified examples\n",
    "wrong_preds_indices = wrong_preds.nonzero().squeeze()\n",
    "\n",
    "# Get the probabiities of the misclassified examples\n",
    "wrong_probs = [round(test_preds_probs[idx].max().item(), 3) for idx in wrong_preds_indices]\n",
    "\n",
    "wrong_preds_labels, true_labels, wrong_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import  Path\n",
    "\n",
    "test_data_paths = [str(path) for path in Path(\"data/pizza_steak_sushi/test\").glob(\"*/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_data = [test_data_paths[idx] for idx in wrong_preds_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    \"samples\": misclassified_data,\n",
    "    \"true_labels\": true_labels,\n",
    "    \"predicted_labels\": wrong_preds_labels,\n",
    "    \"probabilities\": wrong_probs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "top_5_misclassified_samples = df.sort_values(by=[\"probabilities\"], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data\\pizza_steak_sushi\\test\\sushi\\684266.jpg</td>\n",
       "      <td>sushi</td>\n",
       "      <td>steak</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data\\pizza_steak_sushi\\test\\sushi\\1172255.jpg</td>\n",
       "      <td>sushi</td>\n",
       "      <td>steak</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data\\pizza_steak_sushi\\test\\steak\\27415.jpg</td>\n",
       "      <td>steak</td>\n",
       "      <td>sushi</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data\\pizza_steak_sushi\\test\\pizza\\971934.jpg</td>\n",
       "      <td>pizza</td>\n",
       "      <td>sushi</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data\\pizza_steak_sushi\\test\\pizza\\2508636.jpg</td>\n",
       "      <td>pizza</td>\n",
       "      <td>sushi</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         samples true_labels predicted_labels  \\\n",
       "8   data\\pizza_steak_sushi\\test\\sushi\\684266.jpg       sushi            steak   \n",
       "6  data\\pizza_steak_sushi\\test\\sushi\\1172255.jpg       sushi            steak   \n",
       "5    data\\pizza_steak_sushi\\test\\steak\\27415.jpg       steak            sushi   \n",
       "4   data\\pizza_steak_sushi\\test\\pizza\\971934.jpg       pizza            sushi   \n",
       "1  data\\pizza_steak_sushi\\test\\pizza\\2508636.jpg       pizza            sushi   \n",
       "\n",
       "   probabilities  \n",
       "8          0.550  \n",
       "6          0.466  \n",
       "5          0.452  \n",
       "4          0.449  \n",
       "1          0.438  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_misclassified_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHtMeYHuvDwy"
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IvuTskxgjaw"
   },
   "source": [
    "## 3. Predict on your own image of pizza/steak/sushi - how does the model go? What happens if you predict on an image that isn't pizza/steak/sushi?\n",
    "* Here you can get an image from a website like http://www.unsplash.com to try it out or you can upload your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C16glgVFglmG"
   },
   "outputs": [],
   "source": [
    "# TODO: Get an image of pizza/steak/sushi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clA_KmihVYyA"
   },
   "outputs": [],
   "source": [
    "# TODO: Get an image of not pizza/steak/sushi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vzvi8GprgmJ0"
   },
   "source": [
    "## 4. Train the model from section 4  in notebook 06 part 3 for longer (10 epochs should do), what happens to the performance?\n",
    "\n",
    "* See the model in notebook 06 part 3 for reference: https://www.learnpytorch.io/06_pytorch_transfer_learning/#3-getting-a-pretrained-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIKg53Jna-Rt"
   },
   "outputs": [],
   "source": [
    "# TODO: Recreate a new model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhGT9igPgoF5"
   },
   "outputs": [],
   "source": [
    "# TODO: Train the model for 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oRrWPZTgoqL"
   },
   "source": [
    "## 5. Train the model from section 4 above with more data, say 20% of the images from Food101 of Pizza, Steak and Sushi images.\n",
    "* You can find the [20% Pizza, Steak, Sushi dataset](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip) on the course GitHub. It was created with the notebook [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxyMMnUbgvw2"
   },
   "source": [
    "### Get 20% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_fdu5m2eKT9",
    "outputId": "121c61f3-f505-4302-b3b9-8b8bae5b5e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find data/pizza_steak_sushi_20_percent directory, creating one...\n",
      "Downloading pizza, steak, sushi data...\n",
      "Unzipping pizza, steak, sushi 20% data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/pizza_steak_sushi_20_percent/train'),\n",
       " PosixPath('data/pizza_steak_sushi_20_percent/test'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
    "image_data_zip_path = \"pizza_steak_sushi_20_percent.zip\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(data_path / image_data_zip_path, \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / image_data_zip_path, \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi 20% data...\") \n",
    "        zip_ref.extractall(image_path)\n",
    "\n",
    "    # Remove .zip file\n",
    "    os.remove(data_path / image_data_zip_path)\n",
    "\n",
    "# Setup Dirs\n",
    "train_dir_20_percent = image_path / \"train\"\n",
    "test_dir_20_percent = image_path / \"test\"\n",
    "\n",
    "train_dir_20_percent, test_dir_20_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQj7eFdSe4Fv"
   },
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEG_k785e7Jw"
   },
   "outputs": [],
   "source": [
    "# Create a transforms pipeline\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82x7LnQJe7H5",
    "outputId": "342fd4e7-0656-495a-aee0-0d23be130438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f5ede28e390>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f5ede28e210>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and testing DataLoader's as well as get a list of class names\n",
    "train_dataloader_20_percent, test_dataloader_20_percent, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
    "                                                                                                     test_dir=test_dir_20_percent,\n",
    "                                                                                                     transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
    "                                                                                                     batch_size=32) # set mini-batch size to 32\n",
    "\n",
    "train_dataloader_20_percent, test_dataloader_20_percent, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qROl77sKfIOd"
   },
   "source": [
    "### Get a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHWNZ6yDvpR8"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqffJfOIfp3T"
   },
   "source": [
    "### Train a model with 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXpYOYeTvp7a"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ibj4UPjRgvly"
   },
   "source": [
    "## 6. Try a different model from [`torchvision.models`](https://pytorch.org/vision/stable/models.html) on the Pizza, Steak, Sushi data, how does this model perform?\n",
    "* You'll have to change the size of the classifier layer to suit our problem.\n",
    "* You may want to try an EfficientNet with a higher number than our B0, perhaps `torchvision.models.efficientnet_b2()`?\n",
    "  * **Note:** Depending on the model you use you will have to prepare/transform the data in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FQ8tL7El7eO"
   },
   "outputs": [],
   "source": [
    "# TODO "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXgsMoZLpp/LR5qPnNG65Z",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "06_pytorch_transfer_learning_exercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06df3ad4b7454556a43b6d61640b12f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0bdc7325c839439589a16c88876d6bd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fa41d239a3a4845904434d057476a75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2678a567b0414e1d9cfbfc2ecf5ffd30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37424313e66f474da42cfe1b512f09df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc33539914a947ee89c271f10ea6a2bb",
      "placeholder": "",
      "style": "IPY_MODEL_6e03cb60fab94b7e92ce16c8178922dd",
      "value": "100%"
     }
    },
    "4a05e8d965124327a2329cf9e1eec984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4827c6e36a1463fb0c82347f64230a2",
      "placeholder": "",
      "style": "IPY_MODEL_cea8f9c48bd8429998352a090173f537",
      "value": " 5/5 [00:31&lt;00:00,  5.81s/it]"
     }
    },
    "58fd00f6a9114192a4fa757c1f669bff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d464254c31d4516899643112fa0e958",
      "max": 21444401,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06df3ad4b7454556a43b6d61640b12f8",
      "value": 21444401
     }
    },
    "5d464254c31d4516899643112fa0e958": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e03cb60fab94b7e92ce16c8178922dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e25b4bb0d254191a793696a0f4f00ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_37424313e66f474da42cfe1b512f09df",
       "IPY_MODEL_58fd00f6a9114192a4fa757c1f669bff",
       "IPY_MODEL_f115ea4b5fad4bb1910fca49ed3da8a1"
      ],
      "layout": "IPY_MODEL_e8eba8e353e940ff9287929e41e4d656"
     }
    },
    "755366e3f75e44c2b7a79bce78d77d11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce621be138a84f33b24c05b2d9cfd5f0",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fa41d239a3a4845904434d057476a75",
      "value": 5
     }
    },
    "873a483782894789bf0dee546a1b2d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88dea77f1bcf44ffb69654515ee34f54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae21171f17de45d895ab7a319dade609": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9c60d9c0aed49faa993fd865fb09174",
       "IPY_MODEL_755366e3f75e44c2b7a79bce78d77d11",
       "IPY_MODEL_4a05e8d965124327a2329cf9e1eec984"
      ],
      "layout": "IPY_MODEL_fe93ec079b384ac38a6f4d0e505431ff"
     }
    },
    "bc33539914a947ee89c271f10ea6a2bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce621be138a84f33b24c05b2d9cfd5f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cea8f9c48bd8429998352a090173f537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8eba8e353e940ff9287929e41e4d656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f115ea4b5fad4bb1910fca49ed3da8a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bdc7325c839439589a16c88876d6bd5",
      "placeholder": "",
      "style": "IPY_MODEL_873a483782894789bf0dee546a1b2d50",
      "value": " 20.5M/20.5M [00:00&lt;00:00, 61.8MB/s]"
     }
    },
    "f4827c6e36a1463fb0c82347f64230a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9c60d9c0aed49faa993fd865fb09174": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88dea77f1bcf44ffb69654515ee34f54",
      "placeholder": "",
      "style": "IPY_MODEL_2678a567b0414e1d9cfbfc2ecf5ffd30",
      "value": "100%"
     }
    },
    "fe93ec079b384ac38a6f4d0e505431ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
